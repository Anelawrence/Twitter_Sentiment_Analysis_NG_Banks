{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9c833c2",
   "metadata": {},
   "source": [
    "# Twitter Sentiment Analysis of Nigerian Banks\n",
    "### Introduction\n",
    "The banking industry in Nigeria is the most digitized on the continent, and the nation was recently named the leader in digital payments in Africa. A [press release](https://www.businesswire.com/news/home/20220719005265/en/) from 2022 states that Nigeria recorded 3.7 billion real-time payments in 2021, placing it sixth among nations with the largest real-time payments markets.\n",
    "\n",
    "However, due to high inflation, rising interest rates, shortage of US dollars, regulatory interference, and shortage of the Naira notes before the general election in February, weakens bank operating conditions in 2023.\n",
    "\n",
    "### Aims and Objectives\n",
    "This project aims to uncover insights in from bank customers' tweets on Twitter.com. To see how the banks' online customers perceive or react to the respective banks' services.\n",
    "\n",
    "### Project Overview\n",
    "There are three major sections to this project:\n",
    "\n",
    "Data Collection: A python library called Snscrape is used to scrape tweets from Twitter, while pandas is used to read in the scraped data.\n",
    "\n",
    "Data Cleaning and Preprocessing: The libraries used are pandas (for data cleaning and analysis), textblob (for sentiment analysis), and nltk (natural processing language toolkit).\n",
    "\n",
    "Data Analysis and Visualization: For data visualization, the libraries matplotlib, seaborn and wordcloud were used."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dafa87ba",
   "metadata": {},
   "source": [
    "#### Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e16eeb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import snscrape.modules.twitter as sntwitter\n",
    "import itertools\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200d14d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nest_asyncio\n",
    "import re\n",
    "from textblob import TextBlob\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "from nltk.corpus import stopwords   \n",
    "from datetime import datetime\n",
    "import glob                     \n",
    "import os\n",
    "nest_asyncio.apply()\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b7b0ba",
   "metadata": {},
   "source": [
    "### Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805fd671",
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_name={'Guarantee Trust Bank':'gtb OR \\ gtbank',\n",
    "    'Zenith Bank':'zenith bank',\n",
    "    'UBA':'UBA',\n",
    "    'Access Bank':'access bank',\n",
    "    'Fidelity Bank':'fidelity bank',\n",
    "    'Eco Bank':'eco bank',\n",
    "    'First Bank':'first bank',\n",
    "    'Wema Bank':'wema bank',\n",
    "    'Kuda bank':'kuda bank OR \\ kuda',\n",
    "    'FCMB':'fcmb', \n",
    "    'Sterling bank':'sterling bank',\n",
    "    'Opay':'opay',\n",
    "    'Palmpay':'palmpay'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed41b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_config(search_string):\n",
    "    loc = '9.0820, 8.6753, 923768km'\n",
    "    twts = pd.DataFrame(itertools.islice(sntwitter.TwitterSearchScraper(\n",
    "    f'{search_string[1]} + since:2023-01-01 until:2023-05-30 geocode:\"{loc}\"').get_items(), 10000))\n",
    "    return twts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12502abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_snscrape(search_vals):\n",
    "    \n",
    "    #set empty dataframe for join\n",
    "    out_df= pd.DataFrame()\n",
    "    \n",
    "    for bank in search_vals.items():\n",
    "        print (\"running for search item: \"+bank[0]+\"\\n\")\n",
    "        print (\"Search string: \"+bank[1]+\"\\n\")\n",
    "                \n",
    "        #run snscrape\n",
    "        tweets_df = scrape_config(bank)\n",
    "       \n",
    "        #join Dataframes and create 'Bank' column\n",
    "        tweets_df[\"Bank\"]= bank[0]\n",
    "        out_df = pd.concat([out_df,tweets_df])\n",
    "        \n",
    "    return out_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e4d1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df = run_snscrape(bank_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518e0743",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 10000)\n",
    "pd.set_option('display.max_columns', 10000)\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339c18c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0daf292",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88d1e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the dataframe\n",
    "#tweets_df.to_csv('raw_tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a88111",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read saved csv file\n",
    "tweets_df = pd.read_csv('raw_tweets.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3594b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85880084",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf85bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove Unmaned column\n",
    "tweets_df = tweets_df.loc[:, ~tweets_df.columns.str.contains('^Unnamed')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7ab803",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for duplicate tweets\n",
    "tweets_df[tweets_df['rawContent'].duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a5e020",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Drop duplicate tweets\n",
    "tweets_df.drop_duplicates(subset='rawContent', keep=False, inplace=True)\n",
    "tweets_df[tweets_df['rawContent'].duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3cc7a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573c335a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename rawContent to tweet\n",
    "tweets_df.rename(columns = {'rawContent':'tweet'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb09d0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc5e6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to clean tweet column\n",
    "def clean_text(text):  \n",
    "    pat1 = r'@[^ ]+'                   #@signs\n",
    "    pat2 = r'https?://[A-Za-z0-9./]+'  #links\n",
    "    pat3 = r'\\'s'                      #floating s's\n",
    "    pat4 = r'\\#\\w+'                     # hashtags\n",
    "    pat5 = r'&amp '\n",
    "    pat6 = r'[^A-Za-z\\s]'         #remove non-alphabet\n",
    "    pat7 = r'\\n'\n",
    "    combined_pat = r'|'.join((pat1, pat2,pat3,pat4,pat5, pat6, pat7))\n",
    "    text = re.sub(combined_pat,\"\",text).lower()\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb543107",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df[\"tweet\"] = tweets_df[\"tweet\"].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20042063",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df[\"tweet\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f04fec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df[\"lang\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b22294",
   "metadata": {},
   "outputs": [],
   "source": [
    "#droping tweet rows which languange isn't english laguage\n",
    "tweets_df = tweets_df[tweets_df[\"lang\"].isin(['en'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3aaf898",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df[\"lang\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b3401dc",
   "metadata": {},
   "source": [
    "#### Any tweet that contains \"thank you for contacting us\" will be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41217c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "contacting_df = tweets_df.loc[tweets_df['tweet'].str.contains(\"thank you for contacting|thanks for contacting\", case=False)]\n",
    "contacting_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0347d24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df = tweets_df.loc[~(tweets_df['tweet'].str.contains(\"thank you for contacting|thanks for contacting|thank you for reaching out|sorry your message is yet to be responded|apologize for any inconvenience|your complaint via dm\", case=False))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7476b0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['UserName'] = df['url'].str.slice(0, 3)\n",
    "tweets_df['User'] = tweets_df['url'].apply(lambda x: x.split('/')[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dfe194a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting the important columns for this analysis\n",
    "tweets_df = tweets_df[['date', 'tweet', 'likeCount', 'Bank', 'User']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6421a290",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a214fa9a",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1504442b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Running sentiment process\")\n",
    "\n",
    "# creating two new columns(polarity and subjectivity)\n",
    "def getSubjectivity(text):\n",
    "    return TextBlob(text).sentiment.subjectivity\n",
    "def getPolarity(text):\n",
    "    return TextBlob(text).sentiment.polarity\n",
    "\n",
    "tweets_df[\"Subjectivity\"] = tweets_df['tweet'].apply(getSubjectivity)\n",
    "tweets_df[\"Polarity\"] = tweets_df['tweet'].apply(getPolarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1da529",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df[['Subjectivity','Polarity','tweet']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe79b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a column to show if the tweet is positive, negative or neutral\n",
    "def analysis(score):\n",
    "    if score < 0:\n",
    "        return \"Negative\"\n",
    "    elif score == 0:\n",
    "        return \"Neutral\"\n",
    "    else:\n",
    "        return \"Positive\"\n",
    "\n",
    "tweets_df['Analysis'] = tweets_df['Polarity'].apply(analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6936b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df[\"date\"] = pd.to_datetime(tweets_df[\"date\"])\n",
    "\n",
    "# #set index = date so as to create rolling mean \n",
    "# tweets_df = tweets_df.sort_values(\"date\").set_index(\"date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8faa7dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2bbeff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for duplicate tweets\n",
    "tweets_df['tweet'].duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5453c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicate tweets\n",
    "tweets_df.drop_duplicates(subset='tweet', keep=False, inplace=True)\n",
    "tweets_df['tweet'].duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb8a3a2",
   "metadata": {},
   "source": [
    "### Data Visualization and Exploratory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfadc6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting a pie chart to show distribution of Sentiments\n",
    "plt.figure(figsize=[7,5], facecolor='none')\n",
    "plt.pie(tweets_df['Analysis'].value_counts(), labels=['Neutral','Postive', \"Negative\"], colors=['#1dc5af', '#666666', '#E6f2ee'], startangle=90, explode= [0,0,0.09], autopct='%1.1f%%');\n",
    "plt.title('Twitter Users Sentiments');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a564c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(data=tweets_df, x='Bank', hue='Analysis')\n",
    "plt.title('Tweet Analysis of Nigerian Banks'.upper())\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a60e940",
   "metadata": {},
   "source": [
    "#### Creating a word cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e0c131",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import nltk\n",
    "#nltk.download('stopwords')\n",
    "#from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words = stop_words + ['u', 'na', 'know', 'one', 'go', 'make', 'see', 'dont', 'amp', 'im', 'cant']\n",
    "tweets_df['cleaned_words'] = tweets_df['tweet'].astype(str).apply(lambda x: ' '.join([word for word in x.split() if word not in (stop_words)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7beea25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8613b44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the text variable\n",
    "text = \" \".join(i for i in tweets_df.cleaned_words)\n",
    "\n",
    "wc = WordCloud(width = 1000, height = 800, background_color = \"white\").generate(text)\n",
    "\n",
    "#Remove axis and display the data as image\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(wc, interpolation = \"bilinear\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e863d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80214ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save processed tweets as csv\n",
    "tweets_df.to_csv('processed_bank_tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b399681",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
